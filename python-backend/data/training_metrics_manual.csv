iteration,epoch,step,train_loss,validation_loss,learning_rate,batch_size
1,1,1,2.486,2.512,0.001,16
2,1,2,2.312,2.387,0.001,16
3,1,3,2.185,2.223,0.001,16
4,1,4,2.052,2.146,0.001,16
5,1,5,1.988,2.079,0.001,16
6,1,6,1.865,1.923,0.001,16
7,1,7,1.789,1.857,0.001,16
8,1,8,1.723,1.789,0.001,16
9,1,9,1.675,1.735,0.001,16
10,1,10,1.612,1.679,0.001,16
11,1,11,1.587,1.645,0.001,16
12,1,12,1.542,1.598,0.001,16
13,1,13,1.498,1.567,0.001,16
14,1,14,1.467,1.523,0.001,16
15,1,15,1.423,1.489,0.001,16
16,1,16,1.398,1.467,0.001,16
17,1,17,1.367,1.434,0.001,16
18,1,18,1.334,1.398,0.001,16
19,1,19,1.312,1.376,0.001,16
20,1,20,1.287,1.345,0.001,16
21,1,21,1.265,1.323,0.001,16
22,1,22,1.243,1.298,0.001,16
23,1,23,1.223,1.276,0.001,16
24,1,24,1.198,1.254,0.001,16
25,1,25,1.176,1.232,0.001,16
26,1,26,1.156,1.212,0.001,16
27,1,27,1.134,1.189,0.001,16
28,1,28,1.115,1.167,0.001,16
29,1,29,1.098,1.145,0.001,16
30,1,30,1.078,1.123,0.001,16
31,1,31,1.067,1.108,0.001,16
32,1,32,1.054,1.089,0.001,16
33,1,33,1.043,1.076,0.001,16
34,2,1,0.985,1.023,0.0008,16
35,2,2,0.956,0.998,0.0008,16
36,2,3,0.923,0.967,0.0008,16
37,2,4,0.898,0.943,0.0008,16
38,2,5,0.876,0.921,0.0008,16
39,2,6,0.854,0.898,0.0008,16
40,2,7,0.834,0.876,0.0008,16
41,2,8,0.815,0.855,0.0008,16
42,2,9,0.798,0.834,0.0008,16
43,2,10,0.782,0.815,0.0008,16
44,2,11,0.767,0.798,0.0008,16
45,2,12,0.753,0.782,0.0008,16
46,2,13,0.739,0.767,0.0008,16
47,2,14,0.726,0.753,0.0008,16
48,2,15,0.714,0.739,0.0008,16
49,2,16,0.702,0.726,0.0008,16
50,2,17,0.691,0.714,0.0008,16
51,2,18,0.681,0.702,0.0008,16
52,2,19,0.671,0.691,0.0008,16
53,2,20,0.662,0.681,0.0008,16
54,2,21,0.653,0.671,0.0008,16
55,2,22,0.645,0.662,0.0008,16
56,2,23,0.637,0.653,0.0008,16
57,2,24,0.629,0.645,0.0008,16
58,2,25,0.622,0.637,0.0008,16
59,2,26,0.615,0.629,0.0008,16
60,2,27,0.608,0.622,0.0008,16
61,2,28,0.602,0.615,0.0008,16
62,2,29,0.596,0.608,0.0008,16
63,2,30,0.590,0.602,0.0008,16
64,2,31,0.585,0.596,0.0008,16
65,2,32,0.580,0.590,0.0008,16
66,2,33,0.575,0.585,0.0008,16
67,3,1,0.534,0.567,0.0006,16
68,3,2,0.521,0.554,0.0006,16
69,3,3,0.509,0.542,0.0006,16
70,3,4,0.498,0.531,0.0006,16
71,3,5,0.487,0.520,0.0006,16
72,3,6,0.477,0.510,0.0006,16
73,3,7,0.467,0.500,0.0006,16
74,3,8,0.458,0.491,0.0006,16
75,3,9,0.449,0.482,0.0006,16
76,3,10,0.441,0.474,0.0006,16
77,3,11,0.433,0.466,0.0006,16
78,3,12,0.425,0.458,0.0006,16
79,3,13,0.418,0.451,0.0006,16
80,3,14,0.411,0.444,0.0006,16
81,3,15,0.404,0.437,0.0006,16
82,3,16,0.398,0.431,0.0006,16
83,3,17,0.392,0.425,0.0006,16
84,3,18,0.386,0.419,0.0006,16
85,3,19,0.381,0.413,0.0006,16
86,3,20,0.376,0.408,0.0006,16
87,3,21,0.371,0.403,0.0006,16
88,3,22,0.366,0.398,0.0006,16
89,3,23,0.362,0.393,0.0006,16
90,3,24,0.358,0.389,0.0006,16
91,3,25,0.354,0.385,0.0006,16
92,3,26,0.350,0.381,0.0006,16
93,3,27,0.346,0.377,0.0006,16
94,3,28,0.343,0.374,0.0006,16
95,3,29,0.339,0.370,0.0006,16
96,3,30,0.336,0.367,0.0006,16
97,3,31,0.333,0.364,0.0006,16
98,3,32,0.330,0.361,0.0006,16
99,3,33,0.327,0.358,0.0006,16
100,3,34,0.325,0.356,0.0006,16
